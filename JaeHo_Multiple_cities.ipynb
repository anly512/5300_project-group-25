{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestRegression(directory, param):\n",
    "    # listings = pd.read_csv('./data/WashingtonDC/listings.csv')\n",
    "    listings = pd.read_csv(directory, compression='gzip')\n",
    "    df = listings.copy()\n",
    "\n",
    "    df['price_num'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "    df['taken_30'] = 30-df['availability_30']\n",
    "    df['taken_60'] = 60-df['availability_60']\n",
    "\n",
    "    df['sales_30'] = df['taken_30'] * df['price_num']\n",
    "    df['sales_60'] = df['taken_60'] * df['price_num']\n",
    "\n",
    "    # Column types\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'])\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "\n",
    "    specific_date = pd.to_datetime('2024-04-04')\n",
    "    df['host_days_since'] = (specific_date - df['host_since']).dt.days\n",
    "    df['host_desc_len'] = [0 if pd.isna(i) else len(i) for i in df['host_about']]\n",
    "\n",
    "    # Calculate Q1 (25th percentile of the data) for the 'price' column\n",
    "    Q1 = df['price_num'].quantile(0.25)\n",
    "\n",
    "    # Calculate Q3 (75th percentile of the data) for the 'price' column\n",
    "    Q3 = df['price_num'].quantile(0.75)\n",
    "\n",
    "    # Calculate the IQR by subtracting Q1 from Q3\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define bounds for the outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Remove outliers\n",
    "    df_filtered = df[(df['price_num'] <= upper_bound)]\n",
    "\n",
    "    top_10 = df_filtered['neighbourhood_cleansed'].value_counts().head(10).keys()\n",
    "    top10_df = df_filtered[df_filtered['neighbourhood_cleansed'].isin(top_10)]\n",
    "    temp = top10_df[top10_df['neighbourhood_cleansed'].isin(top_10)]\n",
    "    temp = temp[temp['property_type'].str.contains('entire', case=False, na=False)]\n",
    "\n",
    "    df_num = temp[['price_num','latitude','longitude','accommodates','beds','minimum_nights','maximum_nights','number_of_reviews','number_of_reviews_ltm','number_of_reviews_l30d','review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value','calculated_host_listings_count','calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms','calculated_host_listings_count_shared_rooms','reviews_per_month','host_days_since','host_desc_len','neighbourhood_cleansed']]\n",
    "\n",
    "    df_num_drop = df_num.dropna()\n",
    "\n",
    "    # 1. Separate the 'neighbourhood_cleansed' column from the rest of the DataFrame\n",
    "    numerical_features = df_num_drop.drop(['neighbourhood_cleansed'], axis=1)\n",
    "    non_numerical_feature = df_num_drop[['neighbourhood_cleansed']]\n",
    "\n",
    "    # 2. Scale only the numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    numerical_features_scaled = scaler.fit_transform(numerical_features)\n",
    "    df_numerical_scaled = pd.DataFrame(numerical_features_scaled, columns=numerical_features.columns)\n",
    "\n",
    "    # 3. Concatenate the scaled numerical columns and the 'host_is_superhost' column\n",
    "    df_standardized = pd.concat([df_numerical_scaled, non_numerical_feature.reset_index(drop=True)], axis=1)\n",
    "    df_standardized = pd.get_dummies(df_standardized, columns=['neighbourhood_cleansed'])\n",
    "\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X = df_standardized.drop(columns=['price_num'])\n",
    "    y = df_standardized['price_num']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=10, min_samples_leaf=2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Print feature importances\n",
    "    feature_importances = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    # print(\"Top 10 Feature Importances:\\n\", feature_importances[:10])\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "    train_predictions = model.predict(X_train)\n",
    "\n",
    "    # Calculate and print the metrics\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    train_r2 = r2_score(y_train, train_predictions)\n",
    "\n",
    "    return feature_importances, train_r2, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestRegression(directory, param):\n",
    "    # listings = pd.read_csv('./data/WashingtonDC/listings.csv')\n",
    "    listings = pd.read_csv(directory, compression='gzip')\n",
    "    df = listings.copy()\n",
    "\n",
    "    df['price_num'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "    df['taken_30'] = 30-df['availability_30']\n",
    "    df['taken_60'] = 60-df['availability_60']\n",
    "\n",
    "    df['sales_30'] = df['taken_30'] * df['price_num']\n",
    "    df['sales_60'] = df['taken_60'] * df['price_num']\n",
    "\n",
    "    # Column types\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'])\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "\n",
    "    specific_date = pd.to_datetime('2024-04-04')\n",
    "    df['host_days_since'] = (specific_date - df['host_since']).dt.days\n",
    "    df['host_desc_len'] = [0 if pd.isna(i) else len(i) for i in df['host_about']]\n",
    "\n",
    "    # Calculate Q1 (25th percentile of the data) for the 'price' column\n",
    "    Q1 = df['taken_30'].quantile(0.25)\n",
    "\n",
    "    # Calculate Q3 (75th percentile of the data) for the 'price' column\n",
    "    Q3 = df['taken_30'].quantile(0.75)\n",
    "\n",
    "    # Calculate the IQR by subtracting Q1 from Q3\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define bounds for the outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Remove outliers\n",
    "    df_filtered = df[(df['taken_30'] <= upper_bound)]\n",
    "\n",
    "    top_10 = df_filtered['neighbourhood_cleansed'].value_counts().head(10).keys()\n",
    "    top10_df = df_filtered[df_filtered['neighbourhood_cleansed'].isin(top_10)]\n",
    "    temp = top10_df[top10_df['neighbourhood_cleansed'].isin(top_10)]\n",
    "    temp = temp[temp['property_type'].str.contains('entire', case=False, na=False)]\n",
    "\n",
    "    df_num = temp[['taken_30','latitude','longitude','accommodates','beds','minimum_nights','maximum_nights','number_of_reviews','number_of_reviews_ltm','number_of_reviews_l30d','review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value','calculated_host_listings_count','calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms','calculated_host_listings_count_shared_rooms','reviews_per_month','host_days_since','host_desc_len','neighbourhood_cleansed']]\n",
    "\n",
    "    df_num_drop = df_num.dropna()\n",
    "\n",
    "    # 1. Separate the 'neighbourhood_cleansed' column from the rest of the DataFrame\n",
    "    numerical_features = df_num_drop.drop(['neighbourhood_cleansed'], axis=1)\n",
    "    non_numerical_feature = df_num_drop[['neighbourhood_cleansed']]\n",
    "\n",
    "    # 2. Scale only the numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    numerical_features_scaled = scaler.fit_transform(numerical_features)\n",
    "    df_numerical_scaled = pd.DataFrame(numerical_features_scaled, columns=numerical_features.columns)\n",
    "\n",
    "    # 3. Concatenate the scaled numerical columns and the 'host_is_superhost' column\n",
    "    df_standardized = pd.concat([df_numerical_scaled, non_numerical_feature.reset_index(drop=True)], axis=1)\n",
    "    df_standardized = pd.get_dummies(df_standardized, columns=['neighbourhood_cleansed'])\n",
    "\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X = df_standardized.drop(columns=['taken_30'])\n",
    "    y = df_standardized['taken_30']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=10, min_samples_leaf=2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Print feature importances\n",
    "    feature_importances = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    # print(\"Top 10 Feature Importances:\\n\", feature_importances[:10])\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "    train_predictions = model.predict(X_train)\n",
    "\n",
    "    # Calculate and print the metrics\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    train_r2 = r2_score(y_train, train_predictions)\n",
    "\n",
    "    return feature_importances, train_r2, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LosAngeles complete\n",
      "NewYork complete\n",
      "Paris complete\n",
      "Rome complete\n",
      "Seattle complete\n",
      "Singapore complete\n",
      "WashingtonDC complete\n"
     ]
    }
   ],
   "source": [
    "directory_path = './data/'\n",
    "entries = os.listdir('./data/')\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 7,\n",
    "    'min_samples_split':10,\n",
    "    'min_samples_leaf':2\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Loop over each entry and check if it is a directory\n",
    "for entry in entries:\n",
    "    full_path = os.path.join(directory_path, entry)\n",
    "    full_path = full_path + '/listings.csv.gz'\n",
    "\n",
    "    feature, train_r2, test_r2 = RandomForestRegression(full_path,params)\n",
    "\n",
    "    results[entry] = {}\n",
    "    results[entry]['feature_importance'] = feature\n",
    "    results[entry]['train_r2'] = train_r2\n",
    "    results[entry]['test_r2'] = test_r2\n",
    "\n",
    "    print(f\"{entry} complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LosAngeles', 0.1030757061958073),\n",
       " ('NewYork', 0.1449784997969492),\n",
       " ('Paris', 0.140543386034386),\n",
       " ('Rome', 0.12810739876601962),\n",
       " ('Seattle', 0.16527351814092373),\n",
       " ('Singapore', 0.23078877481849147),\n",
       " ('WashingtonDC', 0.07617059004075877)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,results[i]['test_r2']) for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LosAngeles', 0.21754317781838794),\n",
       " ('NewYork', 0.27588499254896226),\n",
       " ('Paris', 0.1947165751975366),\n",
       " ('Rome', 0.20688008671902325),\n",
       " ('Seattle', 0.41635011212861595),\n",
       " ('Singapore', 0.6718576388061162),\n",
       " ('WashingtonDC', 0.3862194438123988)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,results[i]['train_r2']) for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LosAngeles',\n",
       "  calculated_host_listings_count    0.113060\n",
       "  reviews_per_month                 0.104788\n",
       "  latitude                          0.089332\n",
       "  host_days_since                   0.080341\n",
       "  minimum_nights                    0.066419\n",
       "  review_scores_value               0.063612\n",
       "  longitude                         0.058923\n",
       "  number_of_reviews_ltm             0.046604\n",
       "  review_scores_accuracy            0.044014\n",
       "  maximum_nights                    0.038819\n",
       "  dtype: float64),\n",
       " ('NewYork',\n",
       "  minimum_nights                                 0.174774\n",
       "  host_days_since                                0.074633\n",
       "  number_of_reviews_ltm                          0.066715\n",
       "  maximum_nights                                 0.062280\n",
       "  latitude                                       0.061333\n",
       "  longitude                                      0.056496\n",
       "  calculated_host_listings_count_entire_homes    0.055767\n",
       "  number_of_reviews_l30d                         0.053741\n",
       "  reviews_per_month                              0.051041\n",
       "  host_desc_len                                  0.047724\n",
       "  dtype: float64),\n",
       " ('Paris',\n",
       "  number_of_reviews_ltm                          0.303184\n",
       "  calculated_host_listings_count_entire_homes    0.124563\n",
       "  review_scores_value                            0.066333\n",
       "  host_desc_len                                  0.064246\n",
       "  reviews_per_month                              0.063707\n",
       "  host_days_since                                0.056781\n",
       "  minimum_nights                                 0.051564\n",
       "  number_of_reviews                              0.047241\n",
       "  longitude                                      0.035717\n",
       "  maximum_nights                                 0.035472\n",
       "  dtype: float64),\n",
       " ('Rome',\n",
       "  number_of_reviews_ltm             0.263996\n",
       "  number_of_reviews                 0.229748\n",
       "  host_days_since                   0.084230\n",
       "  reviews_per_month                 0.044091\n",
       "  longitude                         0.043581\n",
       "  minimum_nights                    0.043109\n",
       "  calculated_host_listings_count    0.037597\n",
       "  number_of_reviews_l30d            0.037119\n",
       "  latitude                          0.034455\n",
       "  review_scores_value               0.032146\n",
       "  dtype: float64),\n",
       " ('Seattle',\n",
       "  review_scores_accuracy         0.109241\n",
       "  review_scores_communication    0.088239\n",
       "  number_of_reviews_ltm          0.080869\n",
       "  host_days_since                0.069537\n",
       "  latitude                       0.068012\n",
       "  reviews_per_month              0.066182\n",
       "  review_scores_value            0.045797\n",
       "  longitude                      0.045718\n",
       "  host_desc_len                  0.043116\n",
       "  review_scores_checkin          0.040610\n",
       "  dtype: float64),\n",
       " ('Singapore',\n",
       "  reviews_per_month                               0.148733\n",
       "  calculated_host_listings_count                  0.144349\n",
       "  latitude                                        0.110120\n",
       "  host_desc_len                                   0.098689\n",
       "  longitude                                       0.080596\n",
       "  host_days_since                                 0.053992\n",
       "  calculated_host_listings_count_private_rooms    0.043589\n",
       "  beds                                            0.034384\n",
       "  number_of_reviews                               0.030756\n",
       "  accommodates                                    0.029586\n",
       "  dtype: float64),\n",
       " ('WashingtonDC',\n",
       "  number_of_reviews_ltm             0.105589\n",
       "  reviews_per_month                 0.077538\n",
       "  review_scores_communication       0.076500\n",
       "  host_days_since                   0.070121\n",
       "  calculated_host_listings_count    0.062789\n",
       "  host_desc_len                     0.056750\n",
       "  review_scores_value               0.054949\n",
       "  longitude                         0.054080\n",
       "  review_scores_location            0.045369\n",
       "  number_of_reviews                 0.040838\n",
       "  dtype: float64)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,results[i]['feature_importance'][:10]) for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSAN6600",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
